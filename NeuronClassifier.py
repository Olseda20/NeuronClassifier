# Code written to test and classify the the Training.mat and Submission.mat which contain
# voltage data generated by firing neurons. 
# The 'Training.mat' data is first used to train and test the classification algorithm
# Then the full 'Training.mat' is trained and used to classify the neurons in the
# 'Submission.mat' file. What the classification is complete, it saves the index
# and classification data into a new file, 'SubmissionModified.mat'.
# The data dimensionality is first reduced using PCA and then the classification is 
# Completed using KNN.

# Data processing Libraries  
import scipy.io as  spio
from scipy.signal import butter, lfilter, peak_prominences, find_peaks
import numpy as np 
import matplotlib.pyplot as plt 

# Machine Learning Algorithm Libraries 
# PCA for dimensionality reduction
from sklearn.decomposition import PCA
from sklearn.preprocessing import MinMaxScaler
# KNN Classifier Algorithm
from sklearn.neighbors import KNeighborsClassifier

## Allows data to be filtered using a Bandpass filter
def butter_bandpass_filter(data, lowcut, highcut, fs, order=3):
       b, a = butter_bandpass(lowcut, highcut, fs, order=order)
       y = lfilter(b, a, data)
       return y

## Using the Butter filter for the bandpass filter
def butter_bandpass(lowcut, highcut, fs, order=3):
       nyq = 0.5 * fs
       low = lowcut / nyq
       high = highcut / nyq
       b, a = butter(order, [low, high], btype='band')
       return b, a

## Uses the find_peaks function to identify the peaks in the data
def peakDetector(data):
       peakIndex, _ = find_peaks(data, height = 1.5, threshold = None, distance = None, prominence=1, width=None, wlen=None, rel_height=None, plateau_size=None)
       return peakIndex

#Finds a window of interest around an identified index
def peakDataFinder(data, indexPos, pointsBeforePeak,pointsAfterPeak):
       peakFindRange = data[indexPos-pointsBeforePeak:indexPos+pointsAfterPeak]
       return peakFindRange

#Scores the Performance of the Machine Learning Algorithm by comparing 
#Tested Data to preclassified data 
def scorecard (test_data, test_labels,pred):
    scorecard = []
    for i, sample in enumerate(test_data):
        # Check if the KNN classification was correct
        if round(pred[i]) == test_labels[i]:
            scorecard.append(1)
        else:
            scorecard.append(0)
        pass
        # Calculate the performance score, the fraction of correct answers
        scorecard_array = np.asarray(scorecard)
    print("Performance = ", (scorecard_array.sum() / scorecard_array.size) * 100, ' % ')

#Uses PCA and KNN to classify the train and classify input data
def Classify(trainingData, trainingLabels, testingData):
    # Select number of components to extract
    pca = PCA(n_components = 4)

    # Fit to the training data
    pca.fit(trainingData)

    # Determine amount of variance explained by components
    print("Total Variance Explained: ", np.sum(pca.explained_variance_ratio_))

    # Extract the principle components from the training data
    trainingExt = pca.fit_transform(trainingData)

    # Transform the test data using the same components
    testingExt = pca.transform(testingData)

    # Normalise the data sets
    min_max_scaler = MinMaxScaler()
    trainingNorm = min_max_scaler.fit_transform(trainingExt)
    testingNorm = min_max_scaler.fit_transform(testingExt)

    # Create a KNN classification system with k = 5 # Uses the p2 (Euclidean) norm
    knn = KNeighborsClassifier(n_neighbors=4, p=2)
    knn.fit(trainingNorm, trainingLabels)

    # Feed the test data in the classifier to get the predictions
    neurons = knn.predict(testingNorm)
    
    return neurons

#Shows the percentage frequency of every neuron relative the the total neurons 
def showNeuronPercentage(neurons):
    Neuron1 = np.where(neurons==1)
    Neuron2 = np.where(neurons==2)
    Neuron3 = np.where(neurons==3)
    Neuron4 = np.where(neurons==4)
    print('Neuron 1: ',np.array(Neuron1).size/np.array(neurons).size*100,'%')
    print('Neuron 2: ',np.array(Neuron2).size/np.array(neurons).size*100,'%')
    print('Neuron 3: ',np.array(Neuron3).size/np.array(neurons).size*100,'%')
    print('Neuron 4: ',np.array(Neuron4).size/np.array(neurons).size*100,'%')
    return


if __name__ == "__main__":
    
    ######## DATA LOADING ######## 
    # Training Data 
    TrainingMat = spio.loadmat('Training.mat', squeeze_me=True)
    dTraining = TrainingMat['d']

    # Submission Data 
    submissionMat = spio.loadmat('Submission.mat', squeeze_me=True)
    dSubmission = submissionMat['d']


    ######## DATA FILTERING ########
    #Filtering the Training data using a bandpass filter rangeing from 100Hz 2.5K Hz 
    TrainingData = butter_bandpass_filter(dTraining, 100, 2500, 25000, order=3)
    peakIndexTraining = peakDetector(TrainingData) 
    TrainingIndex = TrainingMat['Index']
    TrainingClass = TrainingMat['Class']

    #Filtering the Submission data using a bandpass filter rangeing from 100Hz 2.5K Hz 
    SubmissionData = butter_bandpass_filter(dSubmission, 100, 2000, 25000, order=3)
    SubmissionIndex = peakDetector(SubmissionData)
    SubmissionIndex = np.delete(SubmissionIndex,1) #Always generates false positive

    ######## Implementation of the Data into PCA and KNN  ########
    
    ## Generating the Training and Testing data set 
    # Window Size parameters about the peaks generated
    nDataHigh = 19      # Optimal 19 # Number of data points to be evaluate after the peak
    nDataLow = 9        # Optimal 9  # Number of data points to be evaluate before the peak
    DataOffset = 11     # Optimal 11 # Offset due to shift of the filtered data
    nDataPts = nDataHigh+nDataLow  # Number of Data points being evaluated in the window

    # Creating the peak training data by generating a window of  data for all peak values 
    PeakWindowTraining = np.empty([len(TrainingIndex), nDataPts]) #Initialising PeakWindows
    for i in range (0,len(TrainingIndex)):
        PeakWindowTraining[i] = peakDataFinder(TrainingData,TrainingIndex[i] + DataOffset,nDataLow,nDataHigh)
    # Creating the peak testing data by generating a window of  data for all peak values 
    PeakWindowTesting = np.empty([len(SubmissionIndex), nDataPts]) #Initialising PeakWindows
    for i in range (1,len(SubmissionIndex)):
        PeakWindowTesting[i] = peakDataFinder(SubmissionData,SubmissionIndex[i],nDataLow,nDataHigh)

    ## Training & Testing using Training.mat  
    print('Training & Testing The Classifier')
    # Input of the training data
    trainingNumber = 2600 # Allows for training of some of the data and testing for the remaining
    train_data = PeakWindowTraining[0:trainingNumber] #Peak Windows in some Training Data
    train_labels = TrainingClass[0:trainingNumber]    #Classification of some peaks in Training Data 
    test_data = PeakWindowTraining[trainingNumber:]   #Peak Windows in the remaining Training Data
    test_labels = TrainingClass[trainingNumber:]      # This is where the neuron type is being evaluated

    #Passing Training and Testing data to PCA & KNN to be classified
    trainingNeurons = Classify(train_data, train_labels, test_data) #Trains and tests the Training Data 
    scorecard (test_data, test_labels, trainingNeurons) #Scores the Performance of the ML algorithm  
    showNeuronPercentage(trainingNeurons) #Shows the percentage of every Neuron in the data 

    ##Classifying the Submission Data
    # Input of the Submission data
    train_data = PeakWindowTraining #Peak Windows in the Training Data
    train_labels = TrainingClass    #Classification of peaks in Training Data 
    test_data = PeakWindowTesting   #Peak Windows in the Submission Data

    print('Classifying the Submission data')
    #Passing Training data to PCA & KNN to train 
    #Passing Submission data to be classified
    submissionNeurons = Classify(train_data, train_labels, test_data) #Trains Training and Classifies Submission Data 
    showNeuronPercentage(submissionNeurons) #Shows the percentage of every Neuron in the data

    spio.savemat('SubmissionModified.mat', {"Index":SubmissionIndex,"Class":submissionNeurons})


    #### Data Plotting
    # fig, ax = plt.subplots()
    # x = np.arange(len(TrainingData))
    # ax.plot(x, SubmissionData)
    # ax.plot(SubmissionIndex, SubmissionData[SubmissionIndex], "x")
    # ax.set(xlabel='Sample', ylabel='voltage (mV)',title='Voltage generated by firing neurons ')
    # ax.grid()
    # plt.show()
